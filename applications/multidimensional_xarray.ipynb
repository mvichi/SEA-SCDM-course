{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multidimensional Data and Xarray Fundamentals\n",
    "\n",
    "This tutorial is a modified and simplified version of the [Xarray tutorials](https://xarray-contrib.github.io/xarray-tutorial/index.html). The tutorials are freely available for download on [GitHub](https://github.com/xarray-contrib/xarray-tutorial). Some material has also been taken from the [Geohack week](https://geohackweek.github.io/nDarrays/01-introduction/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "- Understand multidimensional data in geosciences\n",
    "- Provide an overview of xarray\n",
    "- Describe the xarray data structures, the DataArray and the Dataset, and\n",
    "  the components that make them up\n",
    "- Load xarray dataset from a netCDF file\n",
    "- View and set attributes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of multidimensional data\n",
    "\n",
    "Unlabelled, N-dimensional arrays of numbers are the most widely used data structure in scientific computing. Geoscientists have a particular need for structuring their data as arrays. For example, we commonly work with sets of climate variables (e.g. temperature and precipitation) that vary in space and time and are represented on a regularly-spaced grid. Often we need to subset a large global grid to look at data for a particular region, or select a specific time slice. Then we might want to apply statistical functions to these subsetted groups to generate summary information.\n",
    "These data can be treated with NumPy’s ndarray, because we essentially deal with indexed sets of data. These arrays lack a meaningful representation of the metadata associated with their data. Implementing such functionality is left to individual users and domain-specific packages.\n",
    "\n",
    "Real-world datasets are usually more than just raw numbers; they have\n",
    "labels which encode information about how the array values map to locations in\n",
    "space, time, etc.\n",
    "\n",
    "Here is an example of how we might structure a dataset for a weather forecast:\n",
    "\n",
    "<img src=\"http://xarray.pydata.org/en/stable/_images/dataset-diagram.png\" align=\"center\" width=\"80%\">\n",
    "\n",
    "You'll notice multiple data variables (temperature, precipitation), coordinate\n",
    "variables (latitude, longitude), and dimensions (x, y, t). We'll cover how these\n",
    "fit into Xarray's data structures below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conventional Approach: Working with Unlabelled Arrays\n",
    "Multidimensional array data are often stored in user-defined binary formats, and distributed with custom Fortran or C++ libraries used to read and process the data. Users are responsible for setting up their own file structures and custom codes to handle these files. Subsetting the data involves reading everything into an in-memory array, and then using a series of nested loops with conditional statements to look for a specific range of index values associated with the temporal or spatial slice needed. Also, clever use of matrix algebra is often used to summarize data across spatial and temporal dimensions.\n",
    "\n",
    "### Challenges:\n",
    "The biggest challenge in working with N-dimensional arrays in this fashion is the fact that the data are almost disassociated from their metadata. Users are left with the task of tracking the meaning behind array indices using domain-specific software, often leading to inefficiencies and errors. Common pitfalls often occur in in the form of questions like “is the time axis of my array in the first or third index position?”, or “does my array of timestamps still align with my data after resampling?”.\n",
    "\n",
    "### The network Common Data Format\n",
    "The network Common Data Format, or [NetCDF](https://www.unidata.ucar.edu/software/netcdf/docs/faq.html#whatisit), was created in the early 1990s, and set out to solve some of the challenges in working with N-dimensional arrays. Netcdf is a collection of self-describing, machine-independent binary data formats and software tools that facilitate the creation, access and sharing of scientific data stored in N-dimensional arrays, along with metadata describing the contents of each array. Netcdf was built by the climate science community at a time when regional climate models were beginning to produce larger and larger output files. Another format, [HDF5](https://www.hdfgroup.org/), has been used for many applications including distribution of remote sensing datasets. It turns out these two formats are now merging, such that the latest version netCDF-4 is the HDF5 format but with some restrictions.\n",
    "\n",
    "One benefit of Common Data Formats is that they are structured in ways that enable rapid subsetting and analysis using simple command line tools. For example, the climate community has developed their own [netCDF toolkits](http://www.unidata.ucar.edu/software/netcdf/software.html) that accomplish tasks like subsetting and grouping. Similar tools exist for [HDF5](https://support.hdfgroup.org/HDF5/Tutor/HDF5Intro.pdf). Therefore many researchers utilize these tools exclusively in their analysis.\n",
    "\n",
    "### NetCDF in practice\n",
    "NetCDF has been widely adopted as a standard format for distributing N-dimensional arrays. Although many geoscience communities rely entirely on existing NetCDF software tools for processing and visualizing their data, others simply use NetCDF as a convenient format for serializing their arrays. In many applications, existing NetCDF tools do not provide the flexibility needed for a specific research question, and users end up reading arrays into memory. They then perform statistical and subsetting operations using conventional coding methods (e.g. looping over array indices) described above.\n",
    "\n",
    "### Handling large arrays\n",
    "The NetCDF format has no limit on file sizes. However, any analysis tools that read data from a NetCDF array into memory for some computational operation will be limited by that particular machine’s available memory. As many multidimensional datasets grown in size, for example due to increases in model resolution and remote sensing capabilities, we are becoming increasingly limited in our ability to handle these large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Is Xarray?\n",
    "\n",
    "- Xarray expands on the capabilities of NumPy arrays, providing a lot of\n",
    "  streamline data manipulation.\n",
    "\n",
    "- Xarray's interface is based largely on the netCDF data model (variables,\n",
    "  attributes, and dimensions), but it goes beyond the traditional netCDF\n",
    "  interfaces \n",
    "\n",
    "- Xarray is motivated by weather and climate use cases but is **domain agnostic**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xarray Data Structures\n",
    "\n",
    "- xarray has 2 fundamental data structures:\n",
    "\n",
    "  - `DataArray`, which holds single multi-dimensional variables, its coordinates and the attributes\n",
    "  - `Dataset`, which holds multiple variables (each one a DataArray) that potentially share the same coordinates and common global attributes\n",
    "\n",
    "Both classes are most commonly understood by reading data from an existing NetCDF file. The file used in this example contains monthly means of sea surface temperature. This is loaded as a dataset, using the `open_dataset` method\n",
    "\n",
    "If you get an error (**read the error**, it's at the bottom), it may be that the file you want to open is not in this folder, or that netcdf4 is not installed. To install netcdf4, open a terminal and type\n",
    "\n",
    "`conda install netcdf4`\n",
    "\n",
    "restart the kernel and then retry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the mean sea surface temperature dataset (the engine keyword is not necessary)\n",
    "ds = xr.open_dataset(\"./sst.mnmean.nc\", engine=\"netcdf4\")\n",
    "\n",
    "# xarray's HTML representation\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`xarray`, when coupled with the jupyter notebook can show very rich representations of the dataset information, which helps browsing through the attributes and a condensed view of the data.\n",
    "\n",
    "If you prefer a text based representation, you can set the display_style='text' by running the line below\n",
    "`xr.set_options(display_style=\"text\")`\n",
    "Or you can simply display the netCDF information stored in the file that you would obtain with the command `ncdump` run in the terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# netCDF representation\n",
    "ds.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Dataset`\n",
    "\n",
    "- Xarray's `Dataset` is a dict-like container of labeled arrays (`DataArrays`)\n",
    "  with aligned dimensions. - It is designed as an in-memory representation of a\n",
    "  netCDF dataset.\n",
    "- The dict-like interface of the dataset itself can be\n",
    "  used to access any `DataArray` in a `Dataset`. \n",
    "  \n",
    "Datasets have the following key properties:\n",
    "\n",
    "| Attribute   | Description                                                                                                                              |\n",
    "| ----------- | ---------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| `data_vars` | OrderedDict of `DataArray` objects corresponding to data variables.                                                                      |\n",
    "| `dims`      | dictionary mapping from dimension names to the fixed length of each dimension (e.g., {`lat`: 6, `lon`: 6, `time`: 8}).                   |\n",
    "| `coords`    | a dict-like container of arrays (coordinates) that label each point (e.g., 1-dimensional arrays of numbers, datetime objects or strings) |\n",
    "| `attrs`     | OrderedDict holding the metadata pertaining to the dataset (global attributes)                                                                        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the variables in our dataset, including their dimensions (this dataset contains only one variable)\n",
    "ds.data_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coordinates vs dimensions\n",
    "\n",
    "Dimensions and coordinates may seem synonyms, but they are conceptually different in the NetCDF model. \n",
    "\n",
    "- **Dimensions** count the number of elements along each axis of the multidimensional DataArray. \n",
    "    - Dimensions have names to identify them, and they hold the size of the various variables. _The sst variable contained in this DataSet has 3 dimensions (time, lat, lon)_\n",
    "    - You may have several dimensions in a `DataSet`, and not all variables need to have the same dimensions\n",
    "    - The dimension length is stored in the dimension variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset dimensions\n",
    "print('Dimensions are stored in a dict-like object:',ds.dims)\n",
    "print('The length of the Time dimension is:',ds.dims['time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Coordinates** are *variables* in all senses, but they cannot be modified (while variables can). In the most simple NetCDF data-model, a variable with the same name of a dimension is assumed to be a coordinate. \n",
    "    - Coordinates are the system of reference of the data variables\n",
    "    - They allow you to visualize the data in the space they have been defined, to connect the abstract data structure objects to real world objects (locations in space and time);\n",
    "    - Check the output of the `ds.info` command executed above. There are specific attributes (metadata) that indicates that *lat, lon and time* are coordinates (the *axis* attribute). It may also indicate if the coordinate is centred in the spatial grid or it's an average over a temporal period;\n",
    "    - xarray look for the variables with coordinate attributes, and if not found it applies the simple model that variables holding the same name of a dimension are coordinates; \n",
    "    - The coordinate system of this `DataSet` is *regular*, because the coordinates can be represented with one dimensional variables. xarray creates the 2D grids for carrying out any operation on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the dataset coordinates\n",
    "ds.coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives you a quick glimpse at the content of your coordinates, so you can understand\n",
    "- the spatial resolution (distance between coordinates points along the axes)\n",
    "- the temporal frequency\n",
    "\n",
    "The coordinate attributes often give you all the necessary information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract a coordinate variable from the coordinates\n",
    "ds.coords['time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global attributes\n",
    "The `DataSet` object holds all the global attributes contained in the NetCDF file. They are meant to describe the history of the data and usually give you information about the source, who to contact and how to cite the data\n",
    "\n",
    "**Note**: these information exist if the data originator included them. You can tell how poor a data management plan is from the absence of metadata in the global attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset global attributes are stroed in a dictionary object\n",
    "print(type(ds.attrs))\n",
    "ds.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the dictionary allows you to access each single attribute, e.g.\n",
    "ds.attrs['project']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DataArray`\n",
    "\n",
    "Each variable is a `DataArray`. The `DataArray` is xarray's implementation of a labeled, multi-dimensional array.\n",
    "It has several key properties:\n",
    "\n",
    "| Attribute | Description                                                                                                                              |\n",
    "| --------- | ---------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| `data`    | `numpy.ndarray` or `dask.array` holding the array's values.                                                                              |\n",
    "| `dims`    | dimension names for each axis. For example:(`x`, `y`, `z`) (`lat`, `lon`, `time`).                                                       |\n",
    "| `coords`  | a dict-like container of arrays (coordinates) that label each point (e.g., 1-dimensional arrays of numbers, datetime objects or strings) |\n",
    "| `attrs`   | an `OrderedDict` to hold arbitrary attributes/metadata (such as units)                                                                   |\n",
    "| `name`    | an arbitrary name of the array                                                                                                           |\n",
    "\n",
    "The under-the-hood `xarray` engine is `pandas`. Hence, the DataArray can be accessed using the two typical syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show information of the DataArray containing the sst variable\n",
    "ds['sst']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equivalent command\n",
    "ds.sst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The actual (numpy) array data\n",
    "sst = ds.sst.data\n",
    "print(type(sst))\n",
    "sst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because every variable may have *different dimensions, coordinates and attributes*, this information is stored within each `DataArray`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datarray/variable dimensions\n",
    "ds.sst.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datarray/variable coordinates\n",
    "ds.sst.coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting a coordinate variable to find out the spatial resolution\n",
    "ds.sst.lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataarray/variable attributes (specific to this variable only)\n",
    "ds.sst.attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is very quick to set some arbitrary attribute on a data variable/datarray. You just create a new dictionary entry. **Note**: this does not change the file on disk! You need to export it to netcdf, using the method `ds.to_netcdf()`, either creating a new file or overwriting the previous one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.sst.attrs['extended_units'] = 'Degrees Centigrade'\n",
    "ds.sst.attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting and Visualizing data\n",
    "xarray comes with pandas and matplotlib capabilities. Hence you can extract data by indexing and visualize them, also adding the Cartopy mapping features. The matplotlib keywords specifyng the type of plot are passed through the `DataArray.plot()` method. xarray makes a few educated guesses based on the shape of the data you have extracted. If the object is 1D, it shows a timeseries or a line `plot`; if its 2D shows a `pcolormesh` (changing the colormap depending on whether the data are all positive or positive and negative); in all other cases displays a histogram. \n",
    "\n",
    "### Indexing\n",
    "Indexing is used to select specific elements from xarray files. Let’s select some data from the SST `DataArray`. We need to know that this DataArray has dimensions of time and two dimensional space (latitude and longitude): the first array index is time, the second is latitude, and so on.\n",
    "\n",
    "You are probably already used to conventional ways of indexing an array. You would then use positional indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select one variable and pick the first entry along all the axes\n",
    "ds.sst[0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot one timestep (the python convention includes all the other indexes)\n",
    "ds.sst[0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.sst[:,10,0].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method of handling arrays should be familiar to anyone who has worked with arrays in MATLAB or NumPy. Challenges with this approach: \n",
    "- *you need to know the order of the dimensions (time, lat, lon in this case, but it may change in different datasets)* \n",
    "- *it is not simple to associate an integer index position with something meaningful in our data (how do I know that index 10 of the second dimension is latitude 68S?)*\n",
    "\n",
    "For example, we would have to write some function to map a specific date in the time dimension to its associated integer. **Note that even if you are using an array indexing, xarray still preserves the metadata and when you plot the extracted data you obtain an annotated figure!**\n",
    "\n",
    "xarray lets us perform positional indexing using the coordinates instead of integers by using the methods \n",
    "- `isel` extracts data based on positional indexing along the labelled coordinates (you need to know the names, but not the order)\n",
    "- `sel` extracts data using the coordinate values\n",
    "\n",
    "They are equivalent to `iloc` and `loc` methods in `pandas`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = ds.sst\n",
    "da.isel(lon=0,time=10,lat=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.isel(lat=60, lon=40).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With method `da.isel()` you still need to know the correspondence between indexes and values. `da.sel()` allows you to do label-based indexing, with all the power of the pandas timeseries capabilities. In the following example we are also showing how you pass matplotlib keyword arguments (kwarg) through xarray plotting function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.sel(lat=-32, lon=80).plot(figsize=(12,8),marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.sel(lat=50.0, lon=200.0, time=\"2020\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method works if you match the exact coordinates of the data. If the coordinate *label* does not exist, and a `KeyError` is generated. \n",
    "\n",
    "xarray implements the keyword `method` to enable nearest neighbour (inexact) lookups by use of the methods `backfill` or `nearest`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.sel(lat=51.0, lon=200.0, time=\"2020\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.sel(lat=51., lon=200., method='nearest').plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `slice` function can also be used, to select a range of coordinate values. Note that the method parameter `nearest` is not yet supported if any of the arguments to `.sel()` is a slice object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a given period of time\n",
    "da.sel(time=slice('2019-05', '2020-07')).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "but wait, why do we see a histogram? What were you expecting?\n",
    "    \n",
    "<em> Think about the dimension of the extracted object... </em>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing can also be done along other axes\n",
    "da.sel(time='2019-01',lat=-20,lon=slice(-50,80)).plot(marker='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Where are the values with negative longitudes? \n",
    "    \n",
    "<em> A quick look at the lon coordinate will give the answer... </em>\n",
    "    \n",
    "Why there are missing values?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.sel(time='2019-07',lat=slice(-20,-70),lon=slice(250,360)).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping\n",
    "This is very simple. If the axes on which you are plotting the object is a `GeoAxes` instance, the plot becomes a map!\n",
    "Since xarray's default plotting functionality builds on matplotlib, we can\n",
    "seamlessly use cartopy to make nice maps:\n",
    "\n",
    "1. Specify a `projection` for the plot when creating a new axis `axis`.\n",
    "2. Explicitly ask xarray to plot to axis `axis` by passing the keyword argument `ax=axis`.\n",
    "3. Specify the projection of the data using `transform` (`PlateCarree` here) in\n",
    "   `.plot()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "axis = plt.axes(projection=ccrs.PlateCarree())\n",
    "da.sel(time='2019-07').plot(ax=axis,transform=ccrs.PlateCarree(),\n",
    "                           cbar_kwargs={'orientation': 'vertical', 'shrink': 0.6})\n",
    "axis.set_extent([-110,10,-20,-70]) # now you can use all cartopy methods on the axis\n",
    "axis.coastlines()  \n",
    "gl = axis.gridlines(draw_labels=True)\n",
    "gl.right_labels = False\n",
    "gl.top_labels = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(1, 1,figsize=(10,10), subplot_kw=dict(projection=ccrs.Orthographic(0, -30)))\n",
    "\n",
    "ds.sst.isel(time=1).plot(\n",
    "    ax=axis,\n",
    "    transform=ccrs.PlateCarree(),  # this is important since the data are on a mercator projection\n",
    "    vmin=0., vmax=30., # these are matplotlib kwargs\n",
    "    # some arguments passed to control the colorbar\n",
    "    cbar_kwargs={\"orientation\": \"horizontal\", \"shrink\": 0.7},\n",
    "    robust=True,\n",
    ")\n",
    "axis.coastlines()  # now you can use all cartopy methods on the axis\n",
    "axis.gridlines()\n",
    "# The parameter robust=True allows to visualize the data without the outliers, which may change your colorbar limits. \n",
    "# This will use the 2nd and 98th percentiles of the data to compute the color limits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking\n",
    "Indexing methods on xarray objects generally return a subset of the original data. However, it is sometimes useful to select an object with the same shape as the original data, but with some elements masked. An example is selecting a given region, or all the gridpoints that have temperature larger than a given value.\n",
    "\n",
    "To do this type of selection in xarray, we use the method `where()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tropical cyclones develop in regions where the surface temperature is larger than 26 degC\n",
    "da.sel(time='2019-07').where(da>26.).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which is better visualized with the mapping\n",
    "fig,axis = plt.subplots(figsize=(15,7),subplot_kw=dict(projection=ccrs.PlateCarree()))\n",
    "da.sel(time='2019-07').where(da>26.).plot(ax=axis,\n",
    "                                          transform=ccrs.PlateCarree(),\n",
    "                                         cbar_kwargs={'orientation': 'horizontal', 'shrink': 0.8})\n",
    "axis.set_extent([-179,179,40,-40])\n",
    "axis.coastlines()\n",
    "gl=axis.gridlines(draw_labels=True)\n",
    "gl.right_labels=False\n",
    "gl.top_labels=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Masking can also be used to extract a given region and to drop all the other points from the dataset. In this case, you use the keyword `drop=True`. This will return a dataset that is a portion of the original one. \n",
    "\n",
    "_Note: this may be an expensive operation and sometimes it's not efficient. Do it only if you need to reduce the memory footprint._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "mask = np.logical_and((da.lon>0) & (da.lon<=30),(da.lat<-20) & (da.lat>=-36))\n",
    "region = da.sel(time='2019-07').where(mask,drop=True)\n",
    "print(region)\n",
    "region.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going Further\n",
    "\n",
    "- Xarray Documentation on Data Structures:\n",
    "  http://xarray.pydata.org/en/latest/data-structures.html\n",
    "- Xarray Documentation on Reading files and writing files:\n",
    "  https://xarray.pydata.org/en/stable/io.html\n",
    "- Xarrat Documentation on Indexing:\n",
    "  http://xarray.pydata.org/en/stable/indexing.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
